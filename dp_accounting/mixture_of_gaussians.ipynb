{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.sandbox.google.com/github/dvadym/dp/blob/main/dp_accounting/mixture_of_gaussians.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/dvadym/dp/blob/main/dp_accounting/mixture_of_gaussians.ipynb\".ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "rQhUs5OKz5fM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grwmS3V7kOBa"
      },
      "outputs": [],
      "source": [
        "!pip install dp-accounting==0.4.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem setup\n",
        "Let $\\sigma > 0, \\alpha_0\\in [0, 1], \\alpha_2\\in [0, 1]$ be fixed numbers.\n",
        "The goal is to compute discrete PLD with [privacy bucket](https://eprint.iacr.org/2017/1034.pdf) approach for PLD of\n",
        "Gaussian mixtures, i.e.:\n",
        "\n",
        "$$PLD(\\alpha_0N(0, \\sigma^2)+(1-\\alpha_0)N(1, \\sigma^2) || \\alpha_1N(0, \\sigma^2)+(1-\\alpha_1)N(1, \\sigma^2))$$"
      ],
      "metadata": {
        "id": "JPBHVaocymS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0NWKXvckyj7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating PLD for 2 mixture of Gaussians with privacy bucket approach https://eprint.iacr.org/2017/1034.pdf\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from dp_accounting.pld import pld_pmf\n",
        "from dp_accounting.pld import privacy_loss_distribution\n",
        "\n",
        "def inverse_privacy_loss(x:float | np.ndarray, alpha0: float, alpha1: float, sigma: float)->float | np.ndarray:\n",
        "  exp_x = np.exp(x)\n",
        "  nom = exp_x*alpha1 - alpha0\n",
        "  den = 1-alpha0 - exp_x*(1-alpha1)\n",
        "  return 0.5 + sigma**2*np.log(nom/den)\n",
        "\n",
        "\n",
        "def create_pld_pmf(discretization:float,  alpha0: float, alpha1: float, sigma: float, sensitivity:float = 1)->pld_pmf.PLDPmf:\n",
        "  assert (0 < alpha0 < 1) and (0 < alpha1 < 1) # todo: implement inverse case and =0 or =1\n",
        "  # If alpha0 < alpha1:\n",
        "  #   privacy_loss(x) increases so inverse_privacy_loss(x) increases as well,\n",
        "  #   min_loss is np.log(alpha0/alpha1) and achived when x -> -\\infinity\n",
        "  #   max_loss is np.log((1-alpha0)/(1-alpha1)) and achived when x -> \\infinity\n",
        "  # if alpha0 > alpha1:\n",
        "  #   privacy_loss(x) descreases so inverse_privacy_loss(x) descreases as well,\n",
        "  #   min_loss is np.log((1-alpha0)/(1-alpha1)) and achived when x -> \\infinity\n",
        "  #   max_loss is np.log(alpha0/alpha1)  and achived when x -> -\\infinity\n",
        "  # That means that in case of alpha0 > alpha1 we need to carefully inverse\n",
        "  # when it's needed.\n",
        "\n",
        "  sigma /= sensitivity # Normalize sigma.\n",
        "\n",
        "  # Find min anx max loss.\n",
        "  if alpha0 < alpha1:\n",
        "    min_loss = np.log(alpha0/alpha1)\n",
        "    max_loss = np.log((1-alpha0)/(1-alpha1))\n",
        "  else:\n",
        "    min_loss = np.log((1-alpha0)/(1-alpha1))\n",
        "    max_loss = np.log(alpha0/alpha1)\n",
        "  assert min_loss < max_loss\n",
        "  # Create an uniform grid (np.linspace) with discretization such that min_loss\n",
        "  # and max_loss lies between min and max elements of the grid\n",
        "  min_grid_loss = int(np.floor(min_loss/discretization))\n",
        "  max_grid_loss = int(np.ceil(max_loss/discretization))\n",
        "  grid_loss = np.arange(min_grid_loss, max_grid_loss+1)*discretization\n",
        "\n",
        "  # Inverse loss grid values\n",
        "  xs = inverse_privacy_loss(grid_loss, alpha0, alpha1, sigma)\n",
        "\n",
        "  # compute cdf values of the upper distribution.\n",
        "  cdf_values = norm.cdf(xs, loc=0, scale=sigma)\n",
        "  if alpha0 < alpha1:\n",
        "    cdf_values[0], cdf_values[-1] = 0, 1\n",
        "  else:\n",
        "    # privacy_loss(x) decreases, so cdf_values decrease as well\n",
        "    cdf_values[0], cdf_values[-1] = 1, 0\n",
        "  probs = np.diff(cdf_values)\n",
        "  if alpha0 > alpha1:\n",
        "    # privacy_loss(x) is decreasing, so inverse_privacy_loss as well, so\n",
        "    # cdf_values are decreasing, so we need to invert probabilities.\n",
        "    probs = -probs\n",
        "  # Create Privacy Bucket PLD\n",
        "  return pld_pmf.DensePLDPmf(discretization, min_grid_loss+1, probs, infinity_mass=0, pessimistic_estimate=True)\n",
        "\n",
        "def create_pld(discretization:float, alpha0: float, alpha1: float, sigma: float, sensitivity:float = 1):\n",
        "  pld_pmf1 = create_pld_pmf(discretization, alpha0, alpha1, sigma, sensitivity)\n",
        "  pld_pmf2 = create_pld_pmf(discretization, alpha1, alpha0, sigma, sensitivity)\n",
        "  return privacy_loss_distribution.PrivacyLossDistribution(pld_pmf1, pld_pmf2)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iM7QPE8HkY-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how much better than naive composition\n",
        "ALPHA0, ALPHA1 = 0.4, 0.6\n",
        "SIGMA = 3.5\n",
        "DELTA = 1e-10\n",
        "N_MECHANISMS = [1, 2, 5, 10, 100, 1000]\n",
        "DISCRETIZATION = 1e-3 # it controls accuracy/performance tradeoff\n",
        "\n",
        "pld = create_pld(DISCRETIZATION, ALPHA0, ALPHA1, SIGMA)\n",
        "print(f\"{DELTA=} \")\n",
        "for n in N_MECHANISMS:\n",
        "  print(f\"{n} mechanisms: eps =\", pld.self_compose(n).get_epsilon_for_delta(DELTA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QFC8k3blrkh",
        "outputId": "451d7d7a-9db3-4f71-b3f5-71b4636f4699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 mechanisms: eps= 0.26915235911588586\n",
            "2 mechanisms: eps= 0.4222320497012769\n",
            "5 mechanisms: eps= 0.7296331004548241\n",
            "10 mechanisms: eps= 1.086537633545073\n",
            "100 mechanisms: eps= 4.1825334968537815\n",
            "1000 mechanisms: eps= 19.35224047311126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-dbe3b5af0cc9>:12: RuntimeWarning: invalid value encountered in log\n",
            "  return 0.5 + sigma**2*np.log(nom/den)\n"
          ]
        }
      ]
    }
  ]
}
